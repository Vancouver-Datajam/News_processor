{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0701f9b0",
   "metadata": {},
   "source": [
    "# Reading Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "352120e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "                                             message  sentiment\n",
      "0  âˆ’ Scope 3: Optional scope that includes indire...          1\n",
      "1  The Group is not aware of any noise pollution ...          0\n",
      "2  Global climate change could exacerbate certain...          0\n",
      "3  Setting an investment horizon is part and parc...          0\n",
      "4  Climate change the physical impacts of climate...          0\n",
      "Index(['message', 'sentiment'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"climatebert/climate_sentiment\")\n",
    "\n",
    "# Convert the train split to a Pandas DataFrame\n",
    "train_df = dataset['train'].to_pandas()\n",
    "\n",
    "# Convert the test split to a Pandas DataFrame\n",
    "test_df = dataset['test'].to_pandas()\n",
    "\n",
    "# Concatenate train and test dataframes\n",
    "dataframe = pd.concat([train_df, test_df], ignore_index=True)\n",
    "dataframe.columns = ['message', 'sentiment']\n",
    "print(dataframe.head())\n",
    "print(dataframe.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a6abcb",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ca71a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_message(text):\n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Remove special characters and punctuation\n",
    "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to the \"message\" column\n",
    "dataframe['message'] = dataframe['message'].apply(clean_message)\n",
    "\n",
    "def tokenize_message(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "dataframe['tokenized_message'] = dataframe['message'].apply(tokenize_message)\n",
    "\n",
    "# Remove stop words\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))  # Change 'english' to your language if needed\n",
    "\n",
    "def remove_stopwords(tokenized_text):\n",
    "    return [word for word in tokenized_text if word.lower() not in stop_words]\n",
    "\n",
    "dataframe['tokenized_message'] = dataframe['tokenized_message'].apply(remove_stopwords)\n",
    "\n",
    "# Convert all words to lowercase\n",
    "def convert_to_lowercase(tokenized_text):\n",
    "    return [word.lower() for word in tokenized_text]\n",
    "\n",
    "dataframe['tokenized_message'] = dataframe['tokenized_message'].apply(convert_to_lowercase)\n",
    "\n",
    "dataframe = dataframe[['sentiment', 'tokenized_message']]\n",
    "\n",
    "X = dataframe['tokenized_message']\n",
    "y = dataframe['sentiment']\n",
    "X_train, X_test, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert lists of tokens back into strings\n",
    "X_train = X_train.apply(lambda x: ' '.join(x))\n",
    "X_test = X_test.apply(lambda x: ' '.join(x))\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_valid_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c1f0f2",
   "metadata": {},
   "source": [
    "# Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92df3902",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataframe['tokenized_message']\n",
    "y = dataframe['sentiment']\n",
    "X_train, X_test, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7477575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists of tokens back into strings\n",
    "X_train = X_train.apply(lambda x: ' '.join(x))\n",
    "X_test = X_test.apply(lambda x: ' '.join(x))\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_valid_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240da464",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c48e3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Training Accuracy: 0.9545454545454546\n",
      "Logistic Regression Validation Accuracy: 0.7727272727272727\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "logistic_regression = LogisticRegression()\n",
    "# Train the model on the training data\n",
    "logistic_regression.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the training set\n",
    "y_train_pred_lr = logistic_regression.predict(X_train_tfidf)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_valid_pred_lr = logistic_regression.predict(X_valid_tfidf)\n",
    "\n",
    "# Calculate accuracy on the training and validation sets\n",
    "training_accuracy_lr = accuracy_score(y_train, y_train_pred_lr)\n",
    "validation_accuracy_lr = accuracy_score(y_valid, y_valid_pred_lr)\n",
    "\n",
    "print(\"Logistic Regression Training Accuracy:\", training_accuracy_lr)\n",
    "print(\"Logistic Regression Validation Accuracy:\", validation_accuracy_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e558abb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Training Accuracy: 0.6732954545454546\n",
      "Logistic Regression Validation Accuracy: 0.6136363636363636\n"
     ]
    }
   ],
   "source": [
    "# The l1 penalty encourages sparsity in the model by adding a penalty term that\n",
    "# encourages many feature coefficients to be exactly zero. This can be useful when\n",
    "# you suspect that many features are irrelevant or redundant.\n",
    "# The l2 penalty adds a penalty term based on the square of the coefficients' magnitudes.\n",
    "# It discourages coefficients from becoming too large, which helps prevent overfitting.\n",
    "\n",
    "# A smaller C value, such as 0.1, increases the strength of regularization.\n",
    "# In other words, it adds a stronger penalty for large coefficient values.\n",
    "# This can help prevent overfitting by keeping the model's coefficients smaller.\n",
    "\n",
    "logistic_regression = LogisticRegression(penalty='l2', C=0.1, max_iter=1000)\n",
    "\n",
    "# Train the model on the training data\n",
    "logistic_regression.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the training set\n",
    "y_train_pred_lr = logistic_regression.predict(X_train_tfidf)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_valid_pred_lr = logistic_regression.predict(X_valid_tfidf)\n",
    "\n",
    "# Calculate accuracy on the training and validation sets\n",
    "training_accuracy_lr = accuracy_score(y_train, y_train_pred_lr)\n",
    "validation_accuracy_lr = accuracy_score(y_valid, y_valid_pred_lr)\n",
    "\n",
    "print(\"Logistic Regression Training Accuracy:\", training_accuracy_lr)\n",
    "print(\"Logistic Regression Validation Accuracy:\", validation_accuracy_lr)\n",
    "\n",
    "# We successfully reduced overfitting; however, since the dataset has 3 levels (negative, neutral, positive),\n",
    "# and logistic regression is for binary decision, it may not perform optimally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be65628",
   "metadata": {},
   "source": [
    "# Limitation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcc529a",
   "metadata": {},
   "source": [
    "Initially, the Logistic Regression model exhibited strong performance with a training accuracy of 95.45% and a validation accuracy of 77.27%. However, when applied to the sentiment analysis task with three levels (negative, neutral, positive), Logistic Regression struggled to achieve optimal results. This is because Logistic Regression is inherently designed for binary classification, making it less suitable for multi-class problems like ours. The model's performance dropped significantly after tuning, with a training accuracy of 67.33% and a validation accuracy of 61.36%. This decrease in accuracy suggests that despite efforts to reduce overfitting, Logistic Regression may not capture the nuances of multi-class sentiment analysis effectively."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
