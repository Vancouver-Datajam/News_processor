{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# *News Processor Project Front End*"
      ],
      "metadata": {
        "id": "0azXZ1p2qAAX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLE1eNZslE1U"
      },
      "source": [
        "## Introduction\n",
        "This is the front end app of the news processor project.\n",
        "\n",
        "The project goal is to create a tool to detect nuances of Climate news."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Gradio Apps Description\n",
        "\n",
        "Please copy and paste the article you would like to analyze below.\n",
        "\n",
        "There are multiple versions of the app:\n",
        "1. Takes the article input and outputs the text received from the model\n",
        "2. The second app was created by analysing the output from the first app and making a better user interface\n",
        "3. Also rewrites the article in a positive way using OpenAI API\n",
        "\n",
        "`created by: Elgin, Siri`"
      ],
      "metadata": {
        "id": "gos-MRXyo5Fi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import torch\n",
        "import json\n",
        "\n",
        "# Using our own model\n",
        "# saved_model = torch.load(path_to_model_file,map_location=torch.device('cpu'))\n",
        "\n",
        "#\n",
        "# setting up hugging face pipeline\n",
        "from transformers import pipeline\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "def analyze(article_text):\n",
        "    return classifier(article_text)\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    name = gr.Textbox(label=\"Copy and paste your article's text here\", lines=5)\n",
        "    output = gr.Textbox(label=\"This is the article text we analyzed\")\n",
        "    analyze_btn = gr.Button(\"Analyze\")\n",
        "    analyze_btn.click(fn=analyze, inputs=name, outputs=output, api_name=\"analyze\")\n",
        "\n",
        "\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "sE8HkscAo2xG",
        "outputId": "0fbfa448-8e45-4f95-bcec-57f8684d0389"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://0fdab2d04a3aedafe4.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://0fdab2d04a3aedafe4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "slightly improved version, with placeholders for sentiment analysis and %, but it could use some cleaning up because there is a lot of duplicate code\n"
      ],
      "metadata": {
        "id": "67A2x8Getnlw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import torch\n",
        "import json\n",
        "import random\n",
        "\n",
        "# Using our own model\n",
        "# saved_model = torch.load(path_to_model_file,map_location=torch.device('cpu'))\n",
        "\n",
        "#\n",
        "# setting up hugging face pipeline\n",
        "from transformers import pipeline\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "def analyze(article_text):\n",
        "    raw_data = classifier(article_text)\n",
        "    random_choice = raw_data[0]['label']\n",
        "    random_percentage = raw_data[0]['score']*100\n",
        "    formatted_percentage = f'{random_percentage:.2f}%'\n",
        "    return article_text, random_choice, formatted_percentage\n",
        "\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    input1 = gr.Textbox(label=\"Copy and paste your article's text here\", lines=5)\n",
        "    output = gr.Textbox(label=\"This is the article text we analyzed\")\n",
        "    output_sentiment = gr.Textbox(label=\"sentiment\")\n",
        "    output_probability = gr.Textbox(label=\"probability\")\n",
        "    analyze_btn = gr.Button(\"Analyze\")\n",
        "    analyze_btn.click(fn=analyze, inputs=input1, outputs=[output, output_sentiment, output_probability], api_name=\"analyze\")\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        },
        "id": "NcngSswett7z",
        "outputId": "65ecfc87-0969-4057-8b48-9524c8f73753"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7872, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Re-writting Article in a positive note with OpenAI\n",
        "\n",
        "This feature is still being developed."
      ],
      "metadata": {
        "id": "qfn1taoi_zyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "openai.api_key = 'YOUR_API_HERE' # paste your API key here\n",
        "\n",
        "import gradio as gr\n",
        "import torch\n",
        "import json\n",
        "import random\n",
        "\n",
        "# Using our own model\n",
        "# saved_model = torch.load(path_to_model_file,map_location=torch.device('cpu'))\n",
        "\n",
        "#\n",
        "# setting up hugging face pipeline\n",
        "from transformers import pipeline\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "def analyze(article_text):\n",
        "    raw_data = classifier(article_text)\n",
        "    sentiment = raw_data[0]['label']\n",
        "    percentage = raw_data[0]['score']*100\n",
        "    formatted_percentage = f'{percentage:.2f}%'\n",
        "    article_rewrite = \"\"\n",
        "    if(sentiment == 'NEGATIVE'):\n",
        "        article_rewrite = rewrite(article_text)\n",
        "    return article_text, sentiment, formatted_percentage, article_rewrite\n",
        "\n",
        "def rewrite(article_text):\n",
        "    # rewriting using open-ai\n",
        "    prompt = \"Write in positive tone: \"\n",
        "    prompt = prompt + article_text\n",
        "    response = openai.Text.create(user='testing', prompt=prompt, n=1)\n",
        "    return response[\"data\"][0][\"url\"]\n",
        "\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    input1 = gr.Textbox(label=\"Copy and paste your article's text here\", lines=5)\n",
        "    output = gr.Textbox(label=\"This is the article text we analyzed\")\n",
        "    output_sentiment = gr.Textbox(label=\"sentiment\")\n",
        "    output_probability = gr.Textbox(label=\"probability\")\n",
        "    article_rewrite = gr.Textbox(label=\"Article Re-write\", lines=5)\n",
        "    analyze_btn = gr.Button(\"Analyze\")\n",
        "    analyze_btn.click(fn=analyze, inputs=input1, outputs=[output, output_sentiment, output_probability, article_rewrite], api_name=\"analyze\")\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "KBk9EkUD7wRM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.5 64-bit ('3.10.5')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "afcddcb8b5b7b9fe5a2ef76cc89bcf24cd8f6b761938ac67848103e97e668db6"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}